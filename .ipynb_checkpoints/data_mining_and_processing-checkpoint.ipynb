{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c8239b",
   "metadata": {},
   "source": [
    "# üå¶Ô∏è Weather Data Acquisition & Processing Pipeline - Neve Ilan Station (IJERUS70)\n",
    "\n",
    "This notebook manages the data collection for hydrological research. It consolidates weather data from two sources to ensure continuous, high-resolution coverage:\n",
    "\n",
    "1.  **Wunderground (WUG):** Primary source. High-resolution (5-min) data fetched via API.\n",
    "2.  **AWEKAS:** Secondary source. Used to patch data gaps (\"holes\") when WUG data is missing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a7455c",
   "metadata": {},
   "source": [
    "## üì° Part 1: Fetching Data from Wunderground (API)\n",
    "\n",
    "**Description:**\n",
    "This script connects to the Weather Underground History API using your personal API key. It iterates through a specified date range, downloads daily observations, and saves them into a single CSV file.\n",
    "\n",
    "**Key Features:**\n",
    "* **Auto-Recovery:** Calculates `Relative Humidity` if the API only returns Temperature and Dew Point.\n",
    "* **Standardization:** Ensures all units are metric (Celsius, km/h, mm).\n",
    "* **Output:** Saves to `Neve_Ilan_WUG_YYYYMMDD_YYYYMMDD.csv`.\n",
    "\n",
    "**Usage:**\n",
    "Update `start_date` and `end_date` in the configuration section below before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70bba97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting API Scrape: IJERUS70 ---\n",
      "Success: 26/10/2025 - 27 records\n",
      "Success: 27/10/2025 - 0 records\n",
      "Success: 28/10/2025 - 288 records\n",
      "Success: 29/10/2025 - 0 records\n",
      "Success: 30/10/2025 - 288 records\n",
      "Success: 31/10/2025 - 288 records\n",
      "Success: 01/11/2025 - 288 records\n",
      "Success: 02/11/2025 - 287 records\n",
      "Success: 03/11/2025 - 288 records\n",
      "Success: 04/11/2025 - 288 records\n",
      "Success: 05/11/2025 - 288 records\n",
      "Success: 06/11/2025 - 0 records\n",
      "Success: 07/11/2025 - 288 records\n",
      "Success: 08/11/2025 - 288 records\n",
      "Success: 09/11/2025 - 288 records\n",
      "Success: 10/11/2025 - 288 records\n",
      "Success: 11/11/2025 - 0 records\n",
      "Success: 12/11/2025 - 0 records\n",
      "Success: 13/11/2025 - 288 records\n",
      "Success: 14/11/2025 - 281 records\n",
      "Success: 15/11/2025 - 288 records\n",
      "Success: 16/11/2025 - 288 records\n",
      "Success: 17/11/2025 - 288 records\n",
      "Success: 18/11/2025 - 287 records\n",
      "Success: 19/11/2025 - 288 records\n",
      "Success: 20/11/2025 - 0 records\n",
      "Success: 21/11/2025 - 288 records\n",
      "Success: 22/11/2025 - 288 records\n",
      "Success: 23/11/2025 - 0 records\n",
      "Success: 24/11/2025 - 288 records\n",
      "Success: 25/11/2025 - 0 records\n",
      "Success: 26/11/2025 - 288 records\n",
      "Success: 27/11/2025 - 288 records\n",
      "Success: 28/11/2025 - 288 records\n",
      "Success: 29/11/2025 - 288 records\n",
      "Success: 30/11/2025 - 288 records\n",
      "Success: 01/12/2025 - 288 records\n",
      "Success: 02/12/2025 - 288 records\n",
      "Success: 03/12/2025 - 288 records\n",
      "Success: 04/12/2025 - 288 records\n",
      "Success: 05/12/2025 - 288 records\n",
      "Success: 06/12/2025 - 288 records\n",
      "Success: 07/12/2025 - 182 records\n",
      "\n",
      "Resolving time conflicts...\n",
      "Calculating Incremental Precipitation (Continuous)...\n",
      "Done! Saved to: D:\\Development\\RESEARCH\\neve_ilan_station\\WUG\\Neve_Ilan_WUG_20251026_20251207.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def calculate_relative_humidity(T, Td):\n",
    "    \"\"\" Calculates Relative Humidity (%) from Temp and Dew Point using Magnus formula. \"\"\"\n",
    "    a = 17.625\n",
    "    b = 243.04\n",
    "    if pd.isna(T) or pd.isna(Td): return None\n",
    "    try:\n",
    "        numerator = np.exp((a * Td) / (b + Td))\n",
    "        denominator = np.exp((a * T) / (b + T))\n",
    "        rh = 100 * (numerator / denominator)\n",
    "        return round(min(100.0, max(0.0, rh)), 1)\n",
    "    except: return None\n",
    "\n",
    "def smart_resolve_duplicates(df):\n",
    "    \"\"\" Resolves rounding conflicts by moving collisions to the next slot. \"\"\"\n",
    "    df = df.sort_values('Datetime_Obj')\n",
    "    occupied_slots = set(df['Datetime_Round'])\n",
    "    \n",
    "    for i in range(len(df) - 1):\n",
    "        current_round = df.iloc[i]['Datetime_Round']\n",
    "        next_round = df.iloc[i+1]['Datetime_Round']\n",
    "        \n",
    "        if current_round == next_round:\n",
    "            potential_new_slot = current_round + timedelta(minutes=5)\n",
    "            if potential_new_slot not in occupied_slots:\n",
    "                df.at[df.index[i+1], 'Datetime_Round'] = potential_new_slot\n",
    "                occupied_slots.add(potential_new_slot)\n",
    "    return df\n",
    "\n",
    "def fetch_neve_ilan_history_api():\n",
    "    # --- Configuration ---\n",
    "    station_id = \"IJERUS70\"\n",
    "    api_key = \"e1f10a1e78da46f5b10a1e78da96f525\" \n",
    "    output_dir = r\"D:\\Development\\RESEARCH\\neve_ilan_station\\WUG\"\n",
    "    \n",
    "    start_date = datetime(2025, 10, 26)\n",
    "    end_date = datetime.now()\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(f\"--- Starting API Scrape: {station_id} ---\")\n",
    "    all_data = []\n",
    "    current_date = start_date\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime(\"%Y%m%d\")\n",
    "        url = f\"https://api.weather.com/v2/pws/history/all?stationId={station_id}&format=json&units=m&date={date_str}&apiKey={api_key}&numericPrecision=decimal\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if 'observations' in data:\n",
    "                    rows = []\n",
    "                    for obs in data['observations']:\n",
    "                        metric = obs.get('metric', {})\n",
    "                        \n",
    "                        raw_time = obs.get('obsTimeLocal')\n",
    "                        dt_obj = pd.to_datetime(raw_time)\n",
    "                        \n",
    "                        temp, dew = metric.get('tempAvg'), metric.get('dewptAvg')\n",
    "                        hum = obs.get('humidityAvg') if obs.get('humidityAvg') else calculate_relative_humidity(temp, dew)\n",
    "                        \n",
    "                        rows.append({\n",
    "                            'Datetime_Obj': dt_obj,\n",
    "                            'Datetime_Round': dt_obj.round('5min'),\n",
    "                            'Temperature (C)': temp, 'Dew Point (C)': dew, 'Humidity (%)': hum,\n",
    "                            'Wind Speed (km/h)': metric.get('windspeedAvg'), 'Wind Gust (km/h)': metric.get('windgustHigh'),\n",
    "                            'Pressure (hPa)': metric.get('pressureMax'), 'Precip Rate (mm)': metric.get('precipRate'),\n",
    "                            'Precip Accum (mm)': metric.get('precipTotal'), 'Wind Direction': obs.get('winddirAvg'),\n",
    "                            'Solar Radiation (w/m2)': obs.get('solarRadiationHigh'), 'UV': obs.get('uvHigh')\n",
    "                        })\n",
    "                    all_data.append(pd.DataFrame(rows))\n",
    "                    print(f\"Success: {current_date.strftime('%d/%m/%Y')} - {len(rows)} records\")\n",
    "            elif response.status_code == 204:\n",
    "                print(f\"Warning: {current_date.strftime('%d/%m/%Y')} - No Data\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {current_date.strftime('%d/%m/%Y')} - {e}\")\n",
    "            \n",
    "        current_date += timedelta(days=1)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # --- Post-Processing ---\n",
    "    if all_data:\n",
    "        full_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        print(\"\\nResolving time conflicts...\")\n",
    "        full_df = smart_resolve_duplicates(full_df)\n",
    "        full_df = full_df.groupby('Datetime_Round', as_index=False).mean(numeric_only=True)\n",
    "        full_df = full_df.sort_values('Datetime_Round')\n",
    "        \n",
    "        # --- PRECIPITATION STEP CALCULATION (FIXED LOGIC) ---\n",
    "        print(\"Calculating Incremental Precipitation (Continuous)...\")\n",
    "        \n",
    "        # 1. Ensure numeric\n",
    "        full_df['Precip Accum (mm)'] = pd.to_numeric(full_df['Precip Accum (mm)'], errors='coerce').fillna(0.0)\n",
    "        \n",
    "        # 2. Continuous Difference (Ignore Days)\n",
    "        # We calculate the diff from the previous row regardless of the day\n",
    "        full_df['Diff_Raw'] = full_df['Precip Accum (mm)'].diff()\n",
    "        \n",
    "        # 3. Apply Logic using numpy vectorization\n",
    "        # Renamed variable to 'precipitation (mm)' as requested\n",
    "        full_df['precipitation (mm)'] = np.where(\n",
    "            full_df['Diff_Raw'] < 0,      # Condition: Reset detected\n",
    "            full_df['Precip Accum (mm)'], # True: Use current value\n",
    "            full_df['Diff_Raw']           # False: Use difference\n",
    "        )\n",
    "        \n",
    "        # Fill the very first NaN with 0.0\n",
    "        full_df['precipitation (mm)'] = full_df['precipitation (mm)'].fillna(0.0)\n",
    "        \n",
    "        # Round\n",
    "        full_df['precipitation (mm)'] = full_df['precipitation (mm)'].round(2)\n",
    "        # ----------------------------------------------------\n",
    "\n",
    "        # Final Formatting\n",
    "        full_df['Date'] = full_df['Datetime_Round'].dt.strftime('%d/%m/%Y')\n",
    "        full_df['Time'] = full_df['Datetime_Round'].dt.strftime('%H:%M:%S')\n",
    "        \n",
    "        # Clean columns: Removed Rate and Accum columns as requested\n",
    "        # Note: We add them to cols_drop or simply don't include them in target_cols\n",
    "        \n",
    "        target_cols = ['Date', 'Time', \n",
    "                       'Temperature (C)', 'Dew Point (C)', 'Humidity (%)', \n",
    "                       'Wind Speed (km/h)', 'Wind Gust (km/h)', 'Pressure (hPa)', \n",
    "                       'precipitation (mm)', # New name\n",
    "                       'Wind Direction', 'Solar Radiation (w/m2)', 'UV']\n",
    "        \n",
    "        # Ensure all columns exist\n",
    "        for c in target_cols:\n",
    "            if c not in full_df.columns: full_df[c] = None\n",
    "            \n",
    "        # Select only the target columns (This effectively drops Rate and Accum)\n",
    "        full_df = full_df[target_cols]\n",
    "\n",
    "        filename = f\"Neve_Ilan_WUG_{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}.csv\"\n",
    "        full_path = os.path.join(output_dir, filename)\n",
    "        full_df.to_csv(full_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"Done! Saved to: {full_path}\")\n",
    "        \n",
    "\n",
    "# Run\n",
    "fetch_neve_ilan_history_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c08b73",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Part 2: Processing AWEKAS Data (Manual Export)\n",
    "\n",
    "**Description:**\n",
    "This script processes Excel files downloaded manually from AWEKAS. It cleans the data, calculates missing Dew Points, and reformats the columns to match the WUG structure exactly.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Download:** Export data from [AWEKAS](https://www.awekas.at/) (\"My Station\" -> \"Data Import/Export\").\n",
    "2.  **Save:** Place the `.xlsx` file in `D:\\Development\\RESEARCH\\neve_ilan_station\\AWEKAS`.\n",
    "3.  **Configure:** Update the `input_filename` variable below.\n",
    "4.  **Run:** The script will generate a clean CSV named `Neve_Ilan_AWEKAS_START_END.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33ca8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing AWEKAS File: awekas_export_20251026_20251207_row.xlsx ---\n",
      "  > Calculating missing Dew Points...\n",
      "‚úÖ Success! Saved to: Neve_Ilan_AWEKAS_20251026_20251207.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "def calculate_dewpoint(T, RH):\n",
    "    \"\"\" Calculates Dew Point from Temp and Humidity using Magnus formula. \"\"\"\n",
    "    a, b = 17.62, 243.12\n",
    "    if pd.isna(T) or pd.isna(RH) or RH <= 0: return np.nan\n",
    "    try:\n",
    "        alpha = np.log(RH / 100.0) + (a * T) / (b + T)\n",
    "        return round((b * alpha) / (a - alpha), 1)\n",
    "    except: return np.nan\n",
    "\n",
    "def process_awekas_excel_dynamic():\n",
    "    # --- Configuration ---\n",
    "    # UPDATE THIS FILENAME to match your downloaded file\n",
    "    input_filename = \"awekas_export_20251026_20251207_row.xlsx\"\n",
    "    input_path = os.path.join(r\"D:\\Development\\RESEARCH\\neve_ilan_station\\AWEKAS\", input_filename)\n",
    "    \n",
    "    print(f\"--- Processing AWEKAS File: {input_filename} ---\")\n",
    "\n",
    "    # 1. Extract dates from filename for output naming\n",
    "    match = re.search(r\"(\\d{8})_(\\d{8})\", input_filename)\n",
    "    if match:\n",
    "        out_name = f\"Neve_Ilan_AWEKAS_{match.group(1)}_{match.group(2)}.csv\"\n",
    "    else:\n",
    "        out_name = \"Neve_Ilan_AWEKAS_Processed.csv\"\n",
    "        \n",
    "    output_path = os.path.join(os.path.dirname(input_path), out_name)\n",
    "\n",
    "    try:\n",
    "        # 2. Load Data\n",
    "        df = pd.read_excel(input_path, header=0)\n",
    "        \n",
    "        # Remove unit row if it exists (row 2 often contains '¬∞C', 'mm')\n",
    "        if df.iloc[0,0] == 'dd.mm.yyyy': \n",
    "            df = df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "        # 3. Rename columns to WUG Standard\n",
    "        # UPDATED: 'precipitation' -> 'precipitation (mm)'\n",
    "        # REMOVED: 'rainrate' mapping is no longer needed\n",
    "        df.rename(columns={\n",
    "            'date': 'Date_Temp', 'time': 'Time_Temp',\n",
    "            'temperature': 'Temperature (C)', 'humidity': 'Humidity (%)',\n",
    "            'air pressure': 'Pressure (hPa)', \n",
    "            'precipitation': 'precipitation (mm)', # Renamed as requested\n",
    "            'windspeed': 'Wind Speed (km/h)',\n",
    "            'gust speed': 'Wind Gust (km/h)', 'wind direction': 'Wind Direction',\n",
    "            'solar radiation': 'Solar Radiation (w/m2)', 'UV index': 'UV',\n",
    "            'dewpoint': 'Dew Point (C)'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # 4. Cleanup & Calculations\n",
    "        for col in ['Temperature (C)', 'Humidity (%)']: \n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        print(\"  > Calculating missing Dew Points...\")\n",
    "        df['Dew Point (C)'] = df.apply(lambda row: calculate_dewpoint(row['Temperature (C)'], row['Humidity (%)']), axis=1)\n",
    "\n",
    "        # 5. Date & Time Parsing\n",
    "        df['Full_DT'] = pd.to_datetime(df['Date_Temp'].astype(str) + ' ' + df['Time_Temp'].astype(str), format='%d.%m.%Y %H:%M', errors='coerce')\n",
    "        df['Date'] = df['Full_DT'].dt.strftime('%d/%m/%Y')\n",
    "        df['Time'] = df['Full_DT'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "        # 6. Final Structure\n",
    "        # UPDATED: Removed 'Precip Rate (mm)' and used 'precipitation (mm)'\n",
    "        target_cols = ['Date', 'Time', 'Temperature (C)', 'Dew Point (C)', 'Humidity (%)', \n",
    "                       'Wind Speed (km/h)', 'Wind Gust (km/h)', 'Pressure (hPa)', \n",
    "                       'precipitation (mm)', # Matches the other dataset now\n",
    "                       'Wind Direction', \n",
    "                       'Solar Radiation (w/m2)', 'UV']\n",
    "        \n",
    "        # Add missing columns\n",
    "        for col in target_cols: \n",
    "            if col not in df.columns: df[col] = None\n",
    "            \n",
    "        final_df = df.reindex(columns=target_cols).dropna(subset=['Date'])\n",
    "        \n",
    "        # 7. Save\n",
    "        final_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"‚úÖ Success! Saved to: {out_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Run the function\n",
    "process_awekas_excel_dynamic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba27bb70",
   "metadata": {},
   "source": [
    "## üß© Part 3: Merging & Gap Filling (Smart Interpolation)\n",
    "\n",
    "**Description:**\n",
    "Merges the WUG and AWEKAS datasets to create a single, gap-free record. It identifies incomplete days in the primary dataset and reconstructs them using secondary data with physically accurate interpolation logic.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Gap Detection:** Flags and removes any day in WUG with < 50% data coverage.\n",
    "2.  **Resampling:** Converts AWEKAS data to a standard 5-minute resolution.\n",
    "3.  **Smart Interpolation:**\n",
    "    * **General:** Linear interpolation for continuous variables (Temp, Humidity).\n",
    "    * **Rain:** Interpolates *Accumulation* first, then calculates the step difference (preserves total volume).\n",
    "4.  **Output:** Generates the final master file: `Unified_Complete_Weather.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a8154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Smart Merge Process (Fixed Rain Logic) ---\n",
      "Found 9 days to fill/replace from AWEKAS.\n",
      "Interpolating full day: 2025-10-27...\n",
      "Interpolating full day: 2025-10-29...\n",
      "Interpolating full day: 2025-11-06...\n",
      "Interpolating full day: 2025-11-11...\n",
      "Interpolating full day: 2025-11-12...\n",
      "Interpolating full day: 2025-11-20...\n",
      "Interpolating full day: 2025-11-23...\n",
      "Interpolating full day: 2025-11-25...\n",
      "Merging datasets...\n",
      "‚úÖ Success! Unified dataset saved to: D:\\Development\\RESEARCH\\neve_ilan_station\\Unified_Complete_Weather.csv\n",
      "Total Rows: 11975\n",
      "\n",
      "Rain Data Sample (Interpolated Day):\n",
      "Empty DataFrame\n",
      "Columns: [Date, Time, precipitation (mm)]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def merge_and_fill_gaps_smart_v2():\n",
    "    # --- Configuration ---\n",
    "    base_dir = r\"D:\\Development\\RESEARCH\\neve_ilan_station\"\n",
    "    \n",
    "    # Input files\n",
    "    wug_path = os.path.join(base_dir, \"WUG\", \"Neve_Ilan_WUG_20251026_20251207.csv\") \n",
    "    awekas_path = os.path.join(base_dir, \"AWEKAS\", \"Neve_Ilan_AWEKAS_20251026_20251207.csv\")\n",
    "    \n",
    "    # Output file\n",
    "    output_path = os.path.join(base_dir, \"Unified_Complete_Weather.csv\")\n",
    "\n",
    "    print(\"--- Starting Smart Merge Process (Fixed Rain Logic) ---\")\n",
    "\n",
    "    # --- Load Data ---\n",
    "    if not os.path.exists(wug_path) or not os.path.exists(awekas_path):\n",
    "        print(\"Error: Input files not found.\")\n",
    "        return\n",
    "\n",
    "    df_wug = pd.read_csv(wug_path)\n",
    "    df_awekas = pd.read_csv(awekas_path)\n",
    "    \n",
    "    # Create Datetime objects\n",
    "    df_wug['Datetime'] = pd.to_datetime(df_wug['Date'] + ' ' + df_wug['Time'], dayfirst=True)\n",
    "    df_awekas['Datetime'] = pd.to_datetime(df_awekas['Date'] + ' ' + df_awekas['Time'], dayfirst=True)\n",
    "\n",
    "    # --- STEP 1: Identify \"Bad\" Days in WUG ---\n",
    "    daily_counts = df_wug.groupby(df_wug['Datetime'].dt.date).size()\n",
    "    \n",
    "    # Threshold: If a day has less than 50% data (144 records), replace it.\n",
    "    MIN_RECORDS_PER_DAY = 144 \n",
    "    \n",
    "    incomplete_dates = daily_counts[daily_counts < MIN_RECORDS_PER_DAY].index.tolist()\n",
    "    \n",
    "    wug_dates_set = set(df_wug['Datetime'].dt.date)\n",
    "    awekas_dates_set = set(df_awekas['Datetime'].dt.date)\n",
    "    totally_missing_dates = list(awekas_dates_set - wug_dates_set)\n",
    "    \n",
    "    dates_to_fill = sorted(list(set(incomplete_dates + totally_missing_dates)))\n",
    "    \n",
    "    if not dates_to_fill:\n",
    "        print(\"No gaps found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(dates_to_fill)} days to fill/replace from AWEKAS.\")\n",
    "\n",
    "    # --- STEP 2: Clean WUG ---\n",
    "    # Remove the partial days from WUG so we can replace them cleanly\n",
    "    df_wug = df_wug[~df_wug['Datetime'].dt.date.isin(dates_to_fill)]\n",
    "\n",
    "    # --- STEP 3: Process AWEKAS with Correct Rain Logic ---\n",
    "    filled_days_dfs = []\n",
    "    \n",
    "    # Lists for interpolation types\n",
    "    # NOTE: 'precipitation (mm)' is REMOVED from here because it needs special handling\n",
    "    linear_cols = ['Temperature (C)', 'Dew Point (C)', 'Humidity (%)', \n",
    "                   'Wind Speed (km/h)', 'Wind Gust (km/h)', 'Pressure (hPa)', \n",
    "                   'Solar Radiation (w/m2)', 'UV']\n",
    "\n",
    "    for day in dates_to_fill:\n",
    "        if day not in awekas_dates_set:\n",
    "            continue\n",
    "\n",
    "        print(f\"Interpolating full day: {day}...\")\n",
    "        \n",
    "        # Filter AWEKAS data\n",
    "        day_data = df_awekas[df_awekas['Datetime'].dt.date == day].copy()\n",
    "        day_data.set_index('Datetime', inplace=True)\n",
    "        \n",
    "        # Create full 5-min range\n",
    "        full_day_range = pd.date_range(start=f\"{day} 00:00:00\", end=f\"{day} 23:55:00\", freq='5T')\n",
    "        \n",
    "        # Reindex (creates NaNs)\n",
    "        day_resampled = day_data.reindex(full_day_range)\n",
    "        \n",
    "        # 1. Standard Linear Interpolation (Temp, Hum, etc.)\n",
    "        for col in linear_cols:\n",
    "            if col in day_resampled.columns:\n",
    "                day_resampled[col] = pd.to_numeric(day_resampled[col], errors='coerce')\n",
    "                day_resampled[col] = day_resampled[col].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        # 2. SPECIAL RAIN HANDLING (Accumulation -> Diff)\n",
    "        # Assuming 'precipitation (mm)' in AWEKAS is the Daily Accumulation (Standard export format)\n",
    "        if 'precipitation (mm)' in day_resampled.columns:\n",
    "            # a. Interpolate the ACCUMULATION (Smooth the curve of total rain)\n",
    "            day_resampled['precipitation (mm)'] = pd.to_numeric(day_resampled['precipitation (mm)'], errors='coerce')\n",
    "            day_resampled['precipitation (mm)'] = day_resampled['precipitation (mm)'].interpolate(method='linear', limit_direction='both')\n",
    "            \n",
    "            # b. Calculate the STEP (The actual rain per 5 min)\n",
    "            # We take the difference between the current accumulated value and the previous one\n",
    "            day_resampled['precipitation (mm)'] = day_resampled['precipitation (mm)'].diff()\n",
    "            \n",
    "            # c. Fill the very first NaN (usually 0 at midnight) and negative values (if any glitches)\n",
    "            day_resampled['precipitation (mm)'] = day_resampled['precipitation (mm)'].fillna(0)\n",
    "            day_resampled['precipitation (mm)'] = day_resampled['precipitation (mm)'].clip(lower=0)\n",
    "            \n",
    "            # Rounding\n",
    "            day_resampled['precipitation (mm)'] = day_resampled['precipitation (mm)'].round(2)\n",
    "\n",
    "        # 3. Text/Direction Handling (Forward Fill)\n",
    "        if 'Wind Direction' in day_resampled.columns:\n",
    "            day_resampled['Wind Direction'] = day_resampled['Wind Direction'].ffill().bfill()\n",
    "\n",
    "        # Restore columns\n",
    "        day_resampled['Datetime'] = day_resampled.index\n",
    "        day_resampled['Date'] = day_resampled['Datetime'].dt.strftime('%d/%m/%Y')\n",
    "        day_resampled['Time'] = day_resampled['Datetime'].dt.strftime('%H:%M:%S')\n",
    "        \n",
    "        filled_days_dfs.append(day_resampled)\n",
    "\n",
    "    # --- STEP 4: Merge & Save ---\n",
    "    print(\"Merging datasets...\")\n",
    "    if filled_days_dfs:\n",
    "        all_filled_data = pd.concat(filled_days_dfs)\n",
    "        final_df = pd.concat([df_wug, all_filled_data], ignore_index=True)\n",
    "    else:\n",
    "        final_df = df_wug\n",
    "\n",
    "    # Final Sort\n",
    "    final_df['Datetime'] = pd.to_datetime(final_df['Date'] + ' ' + final_df['Time'], dayfirst=True)\n",
    "    final_df = final_df.sort_values('Datetime').reset_index(drop=True)\n",
    "    final_df.drop(columns=['Datetime'], inplace=True)\n",
    "    \n",
    "    # Final Columns Check\n",
    "    target_cols = ['Date', 'Time', 'Temperature (C)', 'Dew Point (C)', 'Humidity (%)', \n",
    "                   'Wind Speed (km/h)', 'Wind Gust (km/h)', 'Pressure (hPa)', \n",
    "                   'precipitation (mm)', 'Wind Direction', \n",
    "                   'Solar Radiation (w/m2)', 'UV']\n",
    "    \n",
    "    for col in target_cols:\n",
    "        if col not in final_df.columns: final_df[col] = None\n",
    "    \n",
    "    final_df = final_df[target_cols]\n",
    "\n",
    "    try:\n",
    "        final_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"‚úÖ Success! Unified dataset saved to: {output_path}\")\n",
    "        print(f\"Total Rows: {len(final_df)}\")\n",
    "        \n",
    "        # Verify Rain Check\n",
    "        print(\"\\nRain Data Sample (Interpolated Day):\")\n",
    "        # Check one of the filled days if exists\n",
    "        if dates_to_fill:\n",
    "            sample_day = dates_to_fill[0].strftime('%d/%m/%Y')\n",
    "            print(final_df[final_df['Date'] == sample_day][['Date', 'Time', 'precipitation (mm)']].head(10))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving: {e}\")\n",
    "\n",
    "# Run\n",
    "merge_and_fill_gaps_smart_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91a4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1eebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
